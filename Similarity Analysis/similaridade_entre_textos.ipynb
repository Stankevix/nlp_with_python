{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cognitive-viewer",
   "metadata": {},
   "source": [
    "# Como determinar a similaridade entre textos em Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "stable-deviation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T15:54:52.013705Z",
     "start_time": "2021-09-27T15:54:52.008715Z"
    }
   },
   "outputs": [],
   "source": [
    "# bibliotecas para carregar as imagens\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-border",
   "metadata": {},
   "source": [
    "## Conceitos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-tissue",
   "metadata": {},
   "source": [
    "### O que é similaridade de texto?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-intranet",
   "metadata": {},
   "source": [
    "A similaridade de texto determina o quão \"próximas\" duas partes do texto estão, tanto em proximidade de superfície **similaridade lexical** e significado **similaridade semântica**.\n",
    "\n",
    "\n",
    "Por exemplo, quão semelhantes são as frases “o gato comeu o rato” com “o rato comeu a comida do gato” apenas olhando para as palavras?\n",
    "\n",
    "* Superficialmente, se você considerar apenas a similaridade no nível da palavra, essas duas frases parecem muito semelhantes, pois 3 das 4 palavras únicas são uma sobreposição exata. Normalmente não leva em consideração o significado real por trás das palavras ou a frase inteira no contexto.\n",
    "* Em vez de fazer uma comparação palavra por palavra, também precisamos prestar atenção ao contexto para capturar mais da semântica. Para considerar a similaridade semântica, precisamos nos concentrar nos níveis de frase / parágrafo (ou nível de cadeia lexica), onde um trecho de texto é dividido em um grupo relevante de palavras relacionadas antes de calcular a similaridade. Sabemos que, embora as palavras se sobreponham significativamente, essas duas frases, na verdade, têm significados diferentes.\n",
    "\n",
    "Existe uma estrutura de dependência em qualquer frase:\n",
    "* rato é o objeto de comer no primeiro caso e comida é o objeto de comer no segundo caso\n",
    "\n",
    "Uma vez que as diferenças na ordem das palavras frequentemente andam de mãos dadas com as diferenças de significado (compare o cachorro morde o homem com o homem morde o cachorro), gostaríamos que nossos encaixes de frases fossem sensíveis a essa variação."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-burden",
   "metadata": {},
   "source": [
    "### Distancia e Similaridade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-ethiopia",
   "metadata": {},
   "source": [
    "Dado dois pontos em um plano cartesiano, para entender como esses dois pontos estão relacionados entre si podemos nos perguntar: \n",
    "\n",
    "* \"Qual a que distância ou quão próximos estão esses dois pontos?\"\n",
    "* A resposta para \"Quão distantes estão esses pontos?\" é a distância deles!\n",
    "* A resposta para \"Quão próximos estão esses pontos?\" é a sua semelhança! \n",
    "\n",
    "Além dessa distinção, similaridade, pode se referir a uma categoria maior de medidas de similaridade, enquanto a distância geralmente se refere a uma categoria menos abrangente que mede a diferença no espaço cartesiano.\n",
    "\n",
    "Pode parecer redundante ou confuso usar os dois termos, mas em análise de texto esses conceitos são geralmente relacionados bem relacionados (ou seja, distância é meramente o oposto de similaridade e vice-versa). \n",
    "\n",
    "No mundo todo, é provável que você encontre os dois termos. Quando medimos por distância, os pontos mais próximos terão a menor distância, mas quando você está medindo por semelhança, os pontos mais próximos terão a maior semelhança. Existem muitas maneiras de calcular a distância entre dois pontos no espaço cartesiano, e diferentes medidas de distância são úteis para diferentes propósitos.\n",
    "\n",
    "Neste documento abordaremos algumas formas de realizar estes calculos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-commission",
   "metadata": {},
   "source": [
    "### Qual é a estrategia ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-involvement",
   "metadata": {},
   "source": [
    "A grande ideia é representar os textos como vetores comparando os textos e medindo a distância entre eles. Existem várias maneiras de computar as distancias que capturam a semântica de textos e vários algoritmos para capturar a estrutura de dependência de textos para enfocar nos significados dos textos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-resistance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T13:16:49.689210Z",
     "start_time": "2021-09-27T13:16:49.672229Z"
    }
   },
   "source": [
    "* Word2Vec + Smooth Inverse Frequency + Cosine Similarity\n",
    "* Different embeddings+ LDA + Jensen-Shannon distance \n",
    "* Different embeddings+ Word Mover Distance \n",
    "* Different embeddings+ Siamese Manhattan LSTM\n",
    "* Fuzzy +  Levenshtein Distance \n",
    "* BERT embeddings + Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-baseball",
   "metadata": {},
   "source": [
    "A word embedding é uma das representações mais populares do vocabulário. \n",
    "\n",
    "É capaz de capturar o contexto de uma palavra em um textos, semelhança semântica e sintática, relação com outras palavras, etc. Abaixo alguns exemplos de modelos de word embedding:\n",
    "\n",
    "* Word2Vec (Google)\n",
    "* GloVe (Stanford)\n",
    "* fastText (Facebook)\n",
    "* Poincarré \n",
    "* Node2Vec embedding baseado em Random Walk e Grafos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-bermuda",
   "metadata": {},
   "source": [
    "## Exemplo do Estudo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-phrase",
   "metadata": {},
   "source": [
    "Uma das coisas que mais serviu como base para outras obras de ficção – e mais recentemente até para a realidade – e que foi invenção de Asimov são as famosas Três Leis da Robótica. Esse conjunto de regras apareceu pela primeira vez em um conto chamado “Círculo Vicioso”, que aparece em “Eu, Robô”. Segundo a história, essas leis teriam surgido pela primeira vez nesse universo em uma publicação chamada “Manual de Robótica, 56ª Edição, 2058 d.C.”.\n",
    "\n",
    "Essas regras deveriam ser implantadas no mais profundo nível das mentes robóticas de maneira que constituíssem as leis mais básicas nas quais essas inteligências artificiais deveriam se pautar e aparecem em praticamente todas as obras do autor, sendo que seus robôs devem obedecê-las (ou a desobediência acaba gerando problemas que são solucionados em suas narrativas).  São elas:\n",
    "\n",
    "* Primeira Lei: Um robô não pode ferir um ser humano ou, por inação, permitir que um ser humano sofra algum mal.\n",
    "* Segunda Lei: Um robô deve obedecer às ordens dadas por seres humanos exceto nos casos em que tais ordens entrem em conflito com a Primeira Lei.\n",
    "* Terceira Lei: Um robô deve proteger sua própria existência desde que tal proteção não entre em conflito com a Primeira ou a Segunda Lei.\n",
    "\n",
    "https://www.tecmundo.com.br/ciencia/125150-funcionam-tres-leis-robotica-escritor-isaac-asimov-2017.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "respective-ontario",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:16:27.405305Z",
     "start_time": "2021-09-27T16:16:27.388323Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_en = [\"A robot may not injure a human being or, through inaction, allow a human being to come to harm.\", \n",
    "          \"A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\",\n",
    "         \"A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vietnamese-dinner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T15:11:59.621687Z",
     "start_time": "2021-10-04T15:11:59.603736Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_pt = [\"Um robô não pode ferir um ser humano ou, por inação, permitir que um ser humano sofra algum mal.\",\n",
    "             \"Um robô deve obedecer às ordens dadas por seres humanos exceto nos casos em que tais ordens entrem em conflito com a Primeira Lei.\",\n",
    "             \"Um robô deve proteger sua própria existência desde que tal proteção não entre em conflito com a Primeira ou a Segunda Lei.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "athletic-project",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-04T15:12:00.138027Z",
     "start_time": "2021-10-04T15:12:00.123106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Um robô não pode ferir um ser humano ou, por inação, permitir que um ser humano sofra algum mal.',\n",
       " 'Um robô deve obedecer às ordens dadas por seres humanos exceto nos casos em que tais ordens entrem em conflito com a Primeira Lei.',\n",
       " 'Um robô deve proteger sua própria existência desde que tal proteção não entre em conflito com a Primeira ou a Segunda Lei.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "blind-bangladesh",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:16:54.556123Z",
     "start_time": "2021-09-27T16:16:54.532187Z"
    }
   },
   "outputs": [],
   "source": [
    "pt_stop_words = {'a', 'à', 'adeus', 'agora', 'aí', 'ainda', 'além', 'algo', 'alguém', 'algum', 'alguma', 'algumas', 'alguns', 'ali', 'ampla', 'amplas', 'amplo', 'amplos', 'ano', 'anos', 'ante', 'antes', 'ao', 'aos', 'apenas', 'apoio', 'após', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aqui', 'aquilo', 'área', 'as', 'às', 'assim', 'até', 'atrás', 'através', 'baixo', 'bastante', 'bem', 'boa', 'boas', 'bom', 'bons', 'breve', 'cá', 'cada', 'catorze', 'cedo', 'cento', 'certamente', 'certeza', 'cima', 'cinco', 'coisa', 'coisas', 'com', 'como', 'conselho', 'contra', 'contudo', 'custa', 'da', 'dá', 'dão', 'daquela', 'daquelas', 'daquele', 'daqueles', 'dar', 'das', 'de', 'debaixo', 'dela', 'delas', 'dele', 'deles', 'demais', 'dentro', 'depois', 'desde', 'dessa', 'dessas', 'desse', 'desses', 'desta', 'destas', 'deste', 'destes', 'deve', 'devem', 'devendo', 'dever', 'deverá', 'deverão', 'deveria', 'deveriam', 'devia', 'deviam', 'dez', 'dezanove', 'dezasseis', 'dezassete', 'dezoito', 'dia', 'diante', 'disse', 'disso', 'disto', 'dito', 'diz', 'dizem', 'dizer', 'do', 'dois', 'dos', 'doze', 'duas', 'dúvida', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'embora', 'enquanto', 'entre', 'era', 'eram', 'éramos', 'és', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estás', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estiveste', 'estivestes', 'estou', 'etc', 'eu', 'exemplo', 'faço', 'falta', 'favor', 'faz', 'fazeis', 'fazem', 'fazemos', 'fazendo', 'fazer', 'fazes', 'feita', 'feitas', 'feito', 'feitos', 'fez', 'fim', 'final', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'forma', 'formos', 'fosse', 'fossem', 'fôssemos', 'foste', 'fostes', 'fui', 'geral', 'grande', 'grandes', 'grupo', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'havia', 'hei', 'hoje', 'hora', 'horas', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'la', 'lá', 'lado', 'lhe', 'lhes', 'lo', 'local', 'logo', 'longe', 'lugar', 'maior', 'maioria', 'mais', 'mal', 'mas', 'máximo', 'me', 'meio', 'menor', 'menos', 'mês', 'meses', 'mesma', 'mesmas', 'mesmo', 'mesmos', 'meu', 'meus', 'mil', 'minha', 'minhas', 'momento', 'muita', 'muitas', 'muito', 'muitos', 'na', 'nada', 'não', 'naquela', 'naquelas', 'naquele', 'naqueles', 'nas', 'nem', 'nenhum', 'nenhuma', 'nessa', 'nessas', 'nesse', 'nesses', 'nesta', 'nestas', 'neste', 'nestes', 'ninguém', 'nível', 'no', 'noite', 'nome', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'nova', 'novas', 'nove', 'novo', 'novos', 'num', 'numa', 'número', 'nunca', 'o', 'obra', 'obrigada', 'obrigado', 'oitava', 'oitavo', 'oito', 'onde', 'ontem', 'onze', 'os', 'ou', 'outra', 'outras', 'outro', 'outros', 'para', 'parece', 'parte', 'partir', 'paucas', 'pela', 'pelas', 'pelo', 'pelos', 'pequena', 'pequenas', 'pequeno', 'pequenos', 'per', 'perante', 'perto', 'pode', 'pude', 'pôde', 'podem', 'podendo', 'poder', 'poderia', 'poderiam', 'podia', 'podiam', 'põe', 'põem', 'pois', 'ponto', 'pontos', 'por', 'porém', 'porque', 'porquê', 'posição', 'possível', 'possivelmente', 'posso', 'pouca', 'poucas', 'pouco', 'poucos', 'primeira', 'primeiras', 'primeiro', 'primeiros', 'própria', 'próprias', 'próprio', 'próprios', 'próxima', 'próximas', 'próximo', 'próximos', 'pude', 'puderam', 'quais', 'quáis', 'qual', 'quando', 'quanto', 'quantos', 'quarta', 'quarto', 'quatro', 'que', 'quê', 'quem', 'quer', 'quereis', 'querem', 'queremas', 'queres', 'quero', 'questão', 'quinta', 'quinto', 'quinze', 'relação', 'sabe', 'sabem', 'são', 'se', 'segunda', 'segundo', 'sei', 'seis', 'seja', 'sejam', 'sejamos', 'sem', 'sempre', 'sendo', 'ser', 'será', 'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'sete', 'sétima', 'sétimo', 'seu', 'seus', 'sexta', 'sexto', 'si', 'sido', 'sim', 'sistema', 'só', 'sob', 'sobre', 'sois', 'somos', 'sou', 'sua', 'suas', 'tal', 'talvez', 'também', 'tampouco', 'tanta', 'tantas', 'tanto', 'tão', 'tarde', 'te', 'tem', 'tém', 'têm', 'temos', 'tendes', 'tendo', 'tenha', 'tenham', 'tenhamos', 'tenho', 'tens', 'ter', 'terá', 'terão', 'terceira', 'terceiro', 'terei', 'teremos', 'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'ti', 'tido', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tiveste', 'tivestes', 'toda', 'todas', 'todavia', 'todo', 'todos', 'trabalho', 'três', 'treze', 'tu', 'tua', 'tuas', 'tudo', 'última', 'últimas', 'último', 'últimos', 'um', 'uma', 'umas', 'uns', 'vai', 'vais', 'vão', 'vários', 'vem', 'vêm', 'vendo', 'vens', 'ver', 'vez', 'vezes', 'viagem', 'vindo', 'vinte', 'vir', 'você', 'vocês', 'vos', 'vós', 'vossa', 'vossas', 'vosso', 'vossos', 'zero', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0', '_'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-thermal",
   "metadata": {},
   "source": [
    "## Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "smart-finance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:20:30.346968Z",
     "start_time": "2021-09-27T16:20:30.326570Z"
    }
   },
   "outputs": [],
   "source": [
    "def stemm_text(text, language):\n",
    "    stemmer = SnowballStemmer(language) # derivacao\n",
    "    #remover pontuacao\n",
    "    remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "    \n",
    "    tokens = [word_tokenize(law.lower().translate(remove_punctuation_map)) for law in text] \n",
    "    stemmed_tokens = [[stemmer.stem(word) for word in token] for token in tokens]\n",
    "\n",
    "    corpus = [ ' '.join(word) for word in stemmed_tokens]\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-champagne",
   "metadata": {},
   "source": [
    "## Distancia Euclidiana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-immunology",
   "metadata": {},
   "source": [
    "A distância euclidiana, batizada em homenagem ao sistema geométrico atribuído ao matemático grego Euclides, permitirá medir uma linha reta. Ela é definida como a soma da raiz quadrada da diferença entre x e y em suas respectivas dimensões.\n",
    "\n",
    "√((x1 – x2)² + (y1 – y2)²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "musical-barrier",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:42:12.215688Z",
     "start_time": "2021-09-27T16:42:12.203721Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "sustainable-supply",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:50:59.139129Z",
     "start_time": "2021-09-27T16:50:59.127174Z"
    }
   },
   "outputs": [],
   "source": [
    "def euclid_dist(corpus):\n",
    "    vectorizer = CountVectorizer(corpus)\n",
    "    wordcounts = vectorizer.fit_transform(corpus).toarray()\n",
    "    euclidean_distances = squareform(pdist(wordcounts))\n",
    "    \n",
    "    return pd.DataFrame(euclidean_distances, index=corpus, columns=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "stable-bosnia",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:50:59.606382Z",
     "start_time": "2021-09-27T16:50:59.587401Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_norm = stemm_text(corpus_pt, \"portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "effective-alloy",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:51:00.167041Z",
     "start_time": "2021-09-27T16:51:00.154075Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass input=['um robô nã pod fer um ser human ou por inaçã permit que um ser human sofr algum mal', 'um robô dev obedec às ordens dad por ser human excet nos cas em que tais ordens entrem em conflit com a primeir lei', 'um robô dev proteg sua própr existent desd que tal proteçã nã entre em conflit com a primeir ou a segund lei'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>um robô nã pod fer um ser human ou por inaçã permit que um ser human sofr algum mal</th>\n",
       "      <th>um robô dev obedec às ordens dad por ser human excet nos cas em que tais ordens entrem em conflit com a primeir lei</th>\n",
       "      <th>um robô dev proteg sua própr existent desd que tal proteçã nã entre em conflit com a primeir ou a segund lei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>um robô nã pod fer um ser human ou por inaçã permit que um ser human sofr algum mal</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.916080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>um robô dev obedec às ordens dad por ser human excet nos cas em que tais ordens entrem em conflit com a primeir lei</th>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.196152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>um robô dev proteg sua própr existent desd que tal proteçã nã entre em conflit com a primeir ou a segund lei</th>\n",
       "      <td>5.91608</td>\n",
       "      <td>5.196152</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    um robô nã pod fer um ser human ou por inaçã permit que um ser human sofr algum mal  \\\n",
       "um robô nã pod fer um ser human ou por inaçã pe...                                            0.00000                                     \n",
       "um robô dev obedec às ordens dad por ser human ...                                            6.00000                                     \n",
       "um robô dev proteg sua própr existent desd que ...                                            5.91608                                     \n",
       "\n",
       "                                                    um robô dev obedec às ordens dad por ser human excet nos cas em que tais ordens entrem em conflit com a primeir lei  \\\n",
       "um robô nã pod fer um ser human ou por inaçã pe...                                           6.000000                                                                     \n",
       "um robô dev obedec às ordens dad por ser human ...                                           0.000000                                                                     \n",
       "um robô dev proteg sua própr existent desd que ...                                           5.196152                                                                     \n",
       "\n",
       "                                                    um robô dev proteg sua própr existent desd que tal proteçã nã entre em conflit com a primeir ou a segund lei  \n",
       "um robô nã pod fer um ser human ou por inaçã pe...                                           5.916080                                                             \n",
       "um robô dev obedec às ordens dad por ser human ...                                           5.196152                                                             \n",
       "um robô dev proteg sua própr existent desd que ...                                           0.000000                                                             "
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = euclid_dist(corpus_norm)\n",
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-squad",
   "metadata": {},
   "source": [
    "## Similaridade de Jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-publisher",
   "metadata": {},
   "source": [
    "O indice de Jaccard aponta a proporção de espécies compartilhadas entre as amostras em relação ao número total de espécies e é dado pela fórmula:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "exciting-mobility",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T15:28:42.865274Z",
     "start_time": "2021-09-27T15:28:42.848313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/jaccard.png\" width=\"200\" height=\"100\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"img/jaccard.png\", width=200, height=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-gamma",
   "metadata": {},
   "source": [
    "* onde “a” é o número de espécies encontrados em ambos os locais (A e B); \n",
    "* “b” é o número total de espécies no local B, mas não em A; \n",
    "* e “c” é o número de espécies no local A, mas não em B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "pharmaceutical-ability",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T14:56:31.771454Z",
     "start_time": "2021-09-27T14:56:31.765464Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "talented-boutique",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:51:48.209961Z",
     "start_time": "2021-09-27T16:51:48.194004Z"
    }
   },
   "outputs": [],
   "source": [
    "def jaccard_sim(str1, str2): \n",
    "    a = set(str1.split()) \n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    \n",
    "    jaccard = float(len(c)) / (len(a) + len(b) - len(c)) \n",
    "    return jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "intelligent-sleeve",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:51:48.631476Z",
     "start_time": "2021-09-27T16:51:48.613530Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_norm = stemm_text(corpus_pt, \"portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "terminal-facial",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:51:49.112560Z",
     "start_time": "2021-09-27T16:51:49.091616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade Lei 1 x Lei 2 0.1935483870967742\n",
      "Similaridade Lei 1 x Lei 3 0.16129032258064516\n",
      "Similaridade Lei 2 x Lei 3 0.30303030303030304\n"
     ]
    }
   ],
   "source": [
    "print(\"Similaridade Lei 1 x Lei 2 {}\".format(jaccard_sim(corpus_norm[0], corpus_norm[1])))\n",
    "print(\"Similaridade Lei 1 x Lei 3 {}\".format(jaccard_sim(corpus_norm[0], corpus_norm[2])))\n",
    "print(\"Similaridade Lei 2 x Lei 3 {}\".format(jaccard_sim(corpus_norm[1], corpus_norm[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-curve",
   "metadata": {},
   "source": [
    "## Similaridade de Cosseno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-seattle",
   "metadata": {},
   "source": [
    "A similaridade de cosseno mede o cosseno do ângulo entre dois vetores. \n",
    "Isso é calculado como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "underlying-capital",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T15:29:35.603163Z",
     "start_time": "2021-09-27T15:29:35.596191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/cosseno.png\" width=\"400\" height=\"150\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"img/cosseno.png\", width=400, height=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-lemon",
   "metadata": {},
   "source": [
    "Com a similaridade de cosseno, precisamos converter sentenças em vetores. \n",
    "\n",
    "Uma maneira de fazer isso é usar um conjunto de palavras como TF (frequência do termo) ou TF-IDF (frequência do termo - frequência inversa do documento).\n",
    "\n",
    "A escolha de TF ou TF-IDF depende da aplicação e é irrelevante para como a similaridade de cosseno é realmente realizada - pois só precisa de vetores. \n",
    "\n",
    "TF é bom para similaridade de texto em geral, mas TF-IDF é bom para relevância de consulta de pesquisa.\n",
    "\n",
    "Outra maneira de calcular a similaridade é usar o Word2Vec ou nossos outros word embeddings personalizados para converter palavras em vetores.\n",
    "\n",
    "Existem duas diferenças principais entre tf / tf-idf com Word embedding :\n",
    "* tf / tf-idf cria um número por palavra, Word embedding normalmente cria um vetor por palavra.\n",
    "2. tf / tf-idf é bom para documentos de classificação como um todo, mas Word embedding são bons para identificar conteúdo contextual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "electronic-valuable",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T14:59:55.348787Z",
     "start_time": "2021-09-27T14:59:55.339780Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "adjustable-youth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:12:57.524100Z",
     "start_time": "2021-09-27T16:12:57.512160Z"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_sim(corpus, stop_words):\n",
    "    vect = TfidfVectorizer(stop_words=stop_words).fit(corpus_norm)\n",
    "    tfidf = vect.transform(corpus_norm)\n",
    "    \n",
    "    # vetor com pesos de cada palavra\n",
    "    txt_df = pd.DataFrame(tfidf.toarray(), columns=vect.get_feature_names()) \n",
    "    \n",
    "    # calcular a similaridade\n",
    "    pairwise_similarity = tfidf * tfidf.T \n",
    "    pairwise_similarity = pd.DataFrame(pairwise_similarity.toarray(), columns=corpus, index=corpus) \n",
    "    \n",
    "    return txt_df, pairwise_similarity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "affecting-bones",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:12:59.291498Z",
     "start_time": "2021-09-27T16:12:59.275537Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_norm = stemm_text(corpus_pt, \"portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "tropical-venice",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:16:05.299531Z",
     "start_time": "2021-09-27T16:16:05.294574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'um robô nã pod fer um ser human ou por inaçã permit que um ser human sofr algum mal'"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "green-intervention",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:13:04.441724Z",
     "start_time": "2021-09-27T16:13:04.426757Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vect, pairwise_similarity = cosine_sim(corpus_norm, pt_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "norman-scratch",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:13:06.252546Z",
     "start_time": "2021-09-27T16:13:06.220666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cas</th>\n",
       "      <th>conflit</th>\n",
       "      <th>dad</th>\n",
       "      <th>desd</th>\n",
       "      <th>dev</th>\n",
       "      <th>entrem</th>\n",
       "      <th>excet</th>\n",
       "      <th>existent</th>\n",
       "      <th>fer</th>\n",
       "      <th>human</th>\n",
       "      <th>...</th>\n",
       "      <th>permit</th>\n",
       "      <th>pod</th>\n",
       "      <th>primeir</th>\n",
       "      <th>proteg</th>\n",
       "      <th>proteçã</th>\n",
       "      <th>própr</th>\n",
       "      <th>robô</th>\n",
       "      <th>segund</th>\n",
       "      <th>sofr</th>\n",
       "      <th>tais</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348349</td>\n",
       "      <td>0.529857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348349</td>\n",
       "      <td>0.348349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.205741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348349</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.274816</td>\n",
       "      <td>0.209005</td>\n",
       "      <td>0.274816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209005</td>\n",
       "      <td>0.274816</td>\n",
       "      <td>0.274816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.274816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328961</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>0.328961</td>\n",
       "      <td>0.328961</td>\n",
       "      <td>0.328961</td>\n",
       "      <td>0.194290</td>\n",
       "      <td>0.328961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cas   conflit       dad      desd       dev    entrem     excet  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1  0.274816  0.209005  0.274816  0.000000  0.209005  0.274816  0.274816   \n",
       "2  0.000000  0.250183  0.000000  0.328961  0.250183  0.000000  0.000000   \n",
       "\n",
       "   existent       fer     human  ...    permit       pod   primeir    proteg  \\\n",
       "0  0.000000  0.348349  0.529857  ...  0.348349  0.348349  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.209005  ...  0.000000  0.000000  0.209005  0.000000   \n",
       "2  0.328961  0.000000  0.000000  ...  0.000000  0.000000  0.250183  0.328961   \n",
       "\n",
       "    proteçã     própr      robô    segund      sofr      tais  \n",
       "0  0.000000  0.000000  0.205741  0.000000  0.348349  0.000000  \n",
       "1  0.000000  0.000000  0.162311  0.000000  0.000000  0.274816  \n",
       "2  0.328961  0.328961  0.194290  0.328961  0.000000  0.000000  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "hearing-index",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:13:10.961674Z",
     "start_time": "2021-09-27T16:13:10.945685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>um robô nã pod fer um ser human ou por inaçã permit que um ser human sofr algum mal</th>\n",
       "      <th>um robô dev obedec às ordens dad por ser human excet nos cas em que tais ordens entrem em conflit com a primeir lei</th>\n",
       "      <th>um robô dev proteg sua própr existent desd que tal proteçã nã entre em conflit com a primeir ou a segund lei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>um robô nã pod fer um ser human ou por inaçã permit que um ser human sofr algum mal</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.144137</td>\n",
       "      <td>0.106254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>um robô dev obedec às ordens dad por ser human excet nos cas em que tais ordens entrem em conflit com a primeir lei</th>\n",
       "      <td>0.144137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.240694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>um robô dev proteg sua própr existent desd que tal proteçã nã entre em conflit com a primeir ou a segund lei</th>\n",
       "      <td>0.106254</td>\n",
       "      <td>0.240694</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    um robô nã pod fer um ser human ou por inaçã permit que um ser human sofr algum mal  \\\n",
       "um robô nã pod fer um ser human ou por inaçã pe...                                           1.000000                                     \n",
       "um robô dev obedec às ordens dad por ser human ...                                           0.144137                                     \n",
       "um robô dev proteg sua própr existent desd que ...                                           0.106254                                     \n",
       "\n",
       "                                                    um robô dev obedec às ordens dad por ser human excet nos cas em que tais ordens entrem em conflit com a primeir lei  \\\n",
       "um robô nã pod fer um ser human ou por inaçã pe...                                           0.144137                                                                     \n",
       "um robô dev obedec às ordens dad por ser human ...                                           1.000000                                                                     \n",
       "um robô dev proteg sua própr existent desd que ...                                           0.240694                                                                     \n",
       "\n",
       "                                                    um robô dev proteg sua própr existent desd que tal proteçã nã entre em conflit com a primeir ou a segund lei  \n",
       "um robô nã pod fer um ser human ou por inaçã pe...                                           0.106254                                                             \n",
       "um robô dev obedec às ordens dad por ser human ...                                           0.240694                                                             \n",
       "um robô dev proteg sua própr existent desd que ...                                           1.000000                                                             "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-murray",
   "metadata": {},
   "source": [
    "https://medium.com/@raivitor/agrupando-frases-usando-similaridade-por-cosseno-c9d7a55be95b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-explosion",
   "metadata": {},
   "source": [
    "## Distancia de Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-program",
   "metadata": {},
   "source": [
    "FuzzyWuzzy é uma biblioteca de Python usada para entender a similaridade entre textos. Esta analise difusas é definida pelo o processo de localização de strings que correspondem a um determinado padrão. Basicamente, ele usa a distância de Levenshtein para calcular as diferenças entre as sequências."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-ultimate",
   "metadata": {},
   "source": [
    "A distância Levenshtein ou distância de edição entre duas \"strings\" (duas sequências de caracteres) é dada pelo número mínimo de operações necessárias para transformar uma string no outra. \n",
    "\n",
    "Entendemos por \"operações\" a inserção, deleção ou substituição de um carácter. O nome advém do cientista russo Vladimir Levenshtein, que considerou esta distância já em 1965. É muito útil para aplicações que precisam determinar quão semelhantes dois strings são, como é por exemplo o caso com os verificadores ortográficos.\n",
    "\n",
    "\n",
    "Por exemplo, a distância Levenshtein entre as palavras inglesas \"kitten\" (gato) e \"sitting\" (sentando-se) é 3, já que com apenas 3 edições conseguimos transformar uma palavra na outra, e não há maneira de o fazer com menos de três edições:\n",
    "\n",
    "* kitten\n",
    "* sitten (substituição de 'k' por 's')\n",
    "* sittin (substituição de 'e' por 'i')\n",
    "* sitting (inserção de 'g' no final)\n",
    "\n",
    "A distância de Levenshtein pode ser considerada como uma generalização da Distância de Hamming, usada para strings com o mesmo tamanho, a qual só considera edições por substituição. Há também outras generalizações da distância Levenshtein que consideram, por exemplo, a troca de dois caracteres como uma aplicação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "polar-disabled",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T14:46:19.373300Z",
     "start_time": "2021-09-27T14:46:19.364296Z"
    }
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "green-complement",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:20:59.266618Z",
     "start_time": "2021-09-27T16:20:59.250659Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_norm = stemm_text(corpus_pt, \"portuguese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "equal-result",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:25:35.652133Z",
     "start_time": "2021-09-27T16:25:35.645152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ratio \n",
      "\n",
      "Similaridade Lei 1 x Lei 2 40\n",
      "Similaridade Lei 1 x Lei 3 30\n",
      "Similaridade Lei 2 x Lei 3 66\n"
     ]
    }
   ],
   "source": [
    "# ratio\n",
    "print (\"\\n ratio \\n\")\n",
    "print(\"Similaridade Lei 1 x Lei 2 {}\".format(fuzz.ratio(corpus_norm[0], corpus_norm[1])))\n",
    "print(\"Similaridade Lei 1 x Lei 3 {}\".format(fuzz.ratio(corpus_norm[0], corpus_norm[2])))\n",
    "print(\"Similaridade Lei 2 x Lei 3 {}\".format(fuzz.ratio(corpus_norm[1], corpus_norm[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-mailman",
   "metadata": {},
   "source": [
    "**Razão Parcial**\n",
    "\n",
    "FuzzyWuzzy também tem funções mais poderosas para ajudar na correspondência de strings em situações mais complexas. A função `fuzz.partial_ratio()` nos permite realizar a correspondência de substring. Isso funciona pegando a string mais curta e combinando-a com todas as substrings do mesmo comprimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "provincial-compatibility",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:25:24.715908Z",
     "start_time": "2021-09-27T16:25:24.680975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " partial_ratio \n",
      "\n",
      "Similaridade Lei 1 x Lei 2 46\n",
      "Similaridade Lei 1 x Lei 3 33\n",
      "Similaridade Lei 2 x Lei 3 59\n"
     ]
    }
   ],
   "source": [
    "#partial_ratio\n",
    "print (\"\\n partial_ratio \\n\")\n",
    "print(\"Similaridade Lei 1 x Lei 2 {}\".format(fuzz.partial_ratio(corpus_norm[0], corpus_norm[1])))\n",
    "print(\"Similaridade Lei 1 x Lei 3 {}\".format(fuzz.partial_ratio(corpus_norm[0], corpus_norm[2])))\n",
    "print(\"Similaridade Lei 2 x Lei 3 {}\".format(fuzz.partial_ratio(corpus_norm[1], corpus_norm[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-edinburgh",
   "metadata": {},
   "source": [
    "**Razão de classificação de token**\n",
    "\n",
    "FuzzyWuzzy também tem funções de token que tokenizar as strings, mudar as maiúsculas para minúsculas e remover a pontuação. A `token_sort_ratio()` função classifica as strings em ordem alfabética e depois as junta. Então, o `fuzz.ratio()` é calculado. Isso pode ser útil quando as strings que você está comparando têm a mesma grafia, mas não estão na mesma ordem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "announced-programmer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:25:14.770836Z",
     "start_time": "2021-09-27T16:25:14.757889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " token_sort_ratio \n",
      "\n",
      "Similaridade Lei 1 x Lei 2 48\n",
      "Similaridade Lei 1 x Lei 3 47\n",
      "Similaridade Lei 2 x Lei 3 65\n"
     ]
    }
   ],
   "source": [
    "#token_sort_ratio\n",
    "#partial_ratio\n",
    "print (\"\\n token_sort_ratio \\n\")\n",
    "print(\"Similaridade Lei 1 x Lei 2 {}\".format(fuzz.token_sort_ratio(corpus_norm[0], corpus_norm[1])))\n",
    "print(\"Similaridade Lei 1 x Lei 3 {}\".format(fuzz.token_sort_ratio(corpus_norm[0], corpus_norm[2])))\n",
    "print(\"Similaridade Lei 2 x Lei 3 {}\".format(fuzz.token_sort_ratio(corpus_norm[1], corpus_norm[2])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-anxiety",
   "metadata": {},
   "source": [
    "A  função `token_set_ratio()` é semelhante à `token_sort_ratio()`, exceto que tira os tokens comuns antes de calcular o fuzz.ratio()entre as novas strings. Essa função é mais útil quando aplicada a um conjunto de strings com uma diferença significativa de comprimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "assured-truck",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:25:59.463155Z",
     "start_time": "2021-09-27T16:25:59.450215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " token_set_ratio \n",
      "\n",
      "Similaridade Lei 1 x Lei 2 55\n",
      "Similaridade Lei 1 x Lei 3 41\n",
      "Similaridade Lei 2 x Lei 3 71\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n token_set_ratio \\n\")\n",
    "print(\"Similaridade Lei 1 x Lei 2 {}\".format(fuzz.token_set_ratio(corpus_norm[0], corpus_norm[1])))\n",
    "print(\"Similaridade Lei 1 x Lei 3 {}\".format(fuzz.token_set_ratio(corpus_norm[0], corpus_norm[2])))\n",
    "print(\"Similaridade Lei 2 x Lei 3 {}\".format(fuzz.token_set_ratio(corpus_norm[1], corpus_norm[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-happening",
   "metadata": {},
   "source": [
    "**Extract**\n",
    "\n",
    "O FuzzyWuzzy também vem com um módulo útil, processo, que retorna as strings junto com uma pontuação de similaridade de um vetor de strings. Tudo que você precisa fazer é chamar a função `extract()` após o processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "graduate-uniform",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-27T16:26:16.586099Z",
     "start_time": "2021-09-27T16:26:16.572106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('um robô nã pod fer um ser human ou por inaçã permit que um ser human sofr algum mal',\n",
       "  36),\n",
       " ('um robô dev obedec às ordens dad por ser human excet nos cas em que tais ordens entrem em conflit com a primeir lei',\n",
       "  32),\n",
       " ('um robô dev proteg sua própr existent desd que tal proteçã nã entre em conflit com a primeir ou a segund lei',\n",
       "  18)]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.extract(\"maldade\", corpus_norm, limit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-packaging",
   "metadata": {},
   "source": [
    "https://ichi.pro/pt/correspondencia-de-string-com-fuzzywuzzy-256747878976132\n",
    "\n",
    "https://pypi.org/project/fuzzywuzzy/\n",
    "\n",
    "https://github.com/ztane/python-Levenshtein/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-evolution",
   "metadata": {},
   "source": [
    "## Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-lying",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-citation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-latest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-climb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changed-characteristic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-passage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-benefit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-qatar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
